{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-afa99aa1cb2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[1;31m#model.add(TimeDistributed(Dense(1,activation='relu')))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m model.compile(loss='mse',\n\u001b[1;32m     38\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "############################### 1) With Embedding ########################################\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Embedding, TimeDistributed\n",
    "\n",
    "import numpy as np\n",
    "embed_dim = 128\n",
    "data_dim = 1\n",
    "timesteps = 25\n",
    "vocab_size = 8100\n",
    "\n",
    "x_old = np.load('idx_q.npy')\n",
    "y_old = np.load('idx_a.npy')\n",
    "\n",
    "keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "embedding = Sequential()\n",
    "embedding.add(Embedding(vocab_size,embed_dim,input_length=timesteps))\n",
    "embedding.compile('rmsprop', 'mse')\n",
    "\n",
    "x = embedding.predict(x_old)\n",
    "y = embedding.predict(y_old)\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "#model.add(Embedding(8100,embed_dim,input_length=timesteps))\n",
    "model.add(LSTM(embed_dim,input_shape=(timesteps,embed_dim),return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "model.add(LSTM(embed_dim,return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "model.add(LSTM(embed_dim,return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "#model.add(TimeDistributed(Dense(1,activation='relu')))\n",
    "\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "\n",
    "# generate dummy training data\n",
    "\n",
    "\n",
    "x_train = x[1:140001].reshape(140000,timesteps,embed_dim)\n",
    "y_train = y[1:140001].reshape(140000,timesteps,embed_dim)\n",
    "# generate dummy validation data\n",
    "x_val = x[140001:150000].reshape(9999,timesteps,embed_dim)\n",
    "y_val = y[140001:150000].reshape(9999,timesteps,embed_dim)\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128, nb_epoch=20,\n",
    "          validation_data=(x_val, y_val))\n",
    "model.save('my_model.h5')\n",
    "x_test = x[150001:160000].reshape(9999,timesteps,embed_dim)\n",
    "y_test = y[150001:160000].reshape(9999,timesteps,embed_dim)\n",
    "score = model.evaluate(x_test, y_test, batch_size=64)\n",
    "print(\"\\nModel Accuracy: %.2f%%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[480337.9356212425, 0.012264528604810367]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c=model.predict(x[40001:40500].reshape(499,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.09884203  0.08344298  0.09658517  0.09359372  0.08724034  0.07723846\n",
      "  0.0680349   0.06117992  0.05216976  0.04656862  0.03937593  0.03422173\n",
      "  0.03021572  0.02661941  0.02194737  0.01883822  0.01598314  0.0128208\n",
      "  0.01082024  0.00868252  0.00629053  0.00474371  0.00292437  0.00145011\n",
      "  0.00017013]\n"
     ]
    }
   ],
   "source": [
    "print(c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140000 samples, validate on 9999 samples\n",
      "Epoch 1/20\n",
      "140000/140000 [==============================] - 186s - loss: 402546.0464 - acc: 0.1487 - val_loss: 432623.3359 - val_acc: 0.0098\n",
      "Epoch 2/20\n",
      "140000/140000 [==============================] - 177s - loss: 402465.1430 - acc: 0.0107 - val_loss: 432610.5873 - val_acc: 0.0110\n",
      "Epoch 3/20\n",
      " 14208/140000 [==>...........................] - ETA: 149s - loss: 399385.0842 - acc: 0.0108"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "############################ 2) Normal LSTM No Embedding #################################\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Embedding, TimeDistributed\n",
    "\n",
    "import numpy as np\n",
    "embed_dim = 128\n",
    "data_dim = 1\n",
    "timesteps = 25\n",
    "vocab_size = 8100\n",
    "\n",
    "x = np.load('idx_q.npy')\n",
    "y = np.load('idx_a.npy')\n",
    "\n",
    "keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "#embedding = Sequential()\n",
    "#embedding.add(Embedding(vocab_size,embed_dim,input_length=timesteps))\n",
    "#embedding.compile('rmsprop', 'mse')\n",
    "\n",
    "#x = embedding.predict(x_old)\n",
    "#y = embedding.predict(y_old)\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(data_dim,input_shape=(timesteps,data_dim),return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "model.add(LSTM(data_dim,return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "model.add(LSTM(data_dim,return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "#model.add(TimeDistributed(Dense(embed_dim,activation='relu')))\n",
    "#model.add(TimeDistributed(Dense(data_dim,activation='relu')))\n",
    "model.compile(loss='mse',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "\n",
    "# generate dummy training data\n",
    "\n",
    "\n",
    "x_train = x[1:140001].reshape(140000,timesteps,data_dim)\n",
    "y_train = y[1:140001].reshape(140000,timesteps,data_dim)\n",
    "# generate dummy validation data\n",
    "x_val = x[140001:150000].reshape(9999,timesteps,data_dim)\n",
    "y_val = y[140001:150000].reshape(9999,timesteps,data_dim)\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128, nb_epoch=20,\n",
    "          validation_data=(x_val, y_val))\n",
    "model.save('my_model.h5')\n",
    "x_test = x[150001:160000].reshape(9999,timesteps,data_dim)\n",
    "y_test = y[150001:160000].reshape(9999,timesteps,data_dim)\n",
    "score = model.evaluate(x_test, y_test, batch_size=64)\n",
    "print(\"\\nModel Accuracy: %.2f%%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140000 samples, validate on 9999 samples\n",
      "Epoch 1/20\n",
      " 70272/140000 [==============>...............] - ETA: 141s - loss: 389574.3568 - acc: 0.0036"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "################################# 3) LSTM One hot ########################################\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Embedding, TimeDistributed\n",
    "\n",
    "import numpy as np\n",
    "embed_dim = 128\n",
    "data_dim = 1\n",
    "timesteps = 25\n",
    "\n",
    "\n",
    "x = np.load('idx_q.npy')\n",
    "y_old = np.load('idx_a.npy')\n",
    "vocab_size = np.amax(y_old)+1\n",
    "y=(np.arange(y_old.max()) == y_old[:,:,None]-1).astype(int)\n",
    "keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "#embedding = Sequential()\n",
    "#embedding.add(Embedding(vocab_size,embed_dim,input_length=timesteps))\n",
    "#embedding.compile('rmsprop', 'mse')\n",
    "\n",
    "#x = embedding.predict(x_old)\n",
    "#y = embedding.predict(y_old)\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(data_dim,input_shape=(timesteps,data_dim),return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "model.add(LSTM(data_dim,return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "model.add(LSTM(data_dim,return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "model.add(TimeDistributed(Dense(vocab_size,activation='softmax')))\n",
    "#model.add(TimeDistributed(Dense(data_dim,activation='relu')))\n",
    "model.compile(loss='mse',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "\n",
    "# generate dummy training data\n",
    "\n",
    "\n",
    "x_train = x[1:140001].reshape(140000,timesteps,data_dim)\n",
    "y_train = y[1:140001].reshape(140000,timesteps,vocab_size)\n",
    "# generate dummy validation data\n",
    "x_val = x[140001:150000].reshape(9999,timesteps,data_dim)\n",
    "y_val = y[140001:150000].reshape(9999,timesteps,vocab_size)\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128, nb_epoch=20,\n",
    "          validation_data=(x_val, y_val))\n",
    "model.save('my_model.h5')\n",
    "x_test = x[150001:160000].reshape(9999,timesteps,data_dim)\n",
    "y_test = y[150001:160000].reshape(9999,timesteps,vocab_size)\n",
    "score = model.evaluate(x_test, y_test, batch_size=64)\n",
    "print(\"\\nModel Accuracy: %.2f%%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "################################# 4) LSTM Time distributed dense #########################\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Embedding, TimeDistributed\n",
    "\n",
    "import numpy as np\n",
    "embed_dim = 128\n",
    "data_dim = 1\n",
    "timesteps = 25\n",
    "\n",
    "keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "#model.add(Embedding(8100,embed_dim,input_length=timesteps))\n",
    "model.add(LSTM(data_dim,return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "model.add(LSTM(data_dim,return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "#model.add(LSTM(data_dim, dropout_W=0.2, dropout_U=0.2))\n",
    "model.add(TimeDistributed(Dense(data_dim,activation='relu')))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "\n",
    "# generate dummy training data\n",
    "x = np.load('idx_q.npy')\n",
    "y = np.load('idx_a.npy')\n",
    "\n",
    "x_train = x[1:140001].reshape(140000,25)\n",
    "y_train = y[1:140001].reshape(140000,25,1)\n",
    "# generate dummy validation data\n",
    "x_val = x[140001:150000].reshape(9999,25)\n",
    "y_val = y[140001:150000].reshape(9999,25,1)\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128, nb_epoch=20,\n",
    "          validation_data=(x_val, y_val))\n",
    "model.save('my_model.h5')\n",
    "x_test = x[150001:160000].reshape(9999,25)\n",
    "y_test = y[150001:160000].reshape(9999,25,1)\n",
    "score = model.evaluate(x_test, y_test, batch_size=64)\n",
    "print(\"\\nModel Accuracy: %.2f%%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = model.predict(X_test,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.29208347]\n"
     ]
    }
   ],
   "source": [
    "print(c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(166559, 25)\n",
      "8001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "x = np.load('idx_q.npy')\n",
    "y = np.load('idx_a.npy')\n",
    "print(x.shape)\n",
    "a=np.array([[1, 7, 5, 3], # Modified the sample listed in question for variety\n",
    "       [2, 4, 1, 4]])\n",
    "\n",
    "#b=(np.arange(y.max()) == y[:,:,None]-1).astype(int)\n",
    "#b=np.eye(8100)[y]\n",
    "print(np.amax(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
