{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Loaded word_frequencies data from disk\n",
      "1 -1\n",
      "(1, 30, 301)\n",
      "night last night nice ! being being being : business business business business business business business business business business business business business business business business business business business business business\n",
      "1 -1\n",
      "(1, 30, 301)\n",
      "night night night ! ! ! go business business business business business business business business business business business business business business business business business business business business business business business\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/lib-tk/Tkinter.py\", line 1489, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-7-4336df07d4f2>\", line 190, in get_response\n",
      "    response = self.neuralbot.model_response(user_input)\n",
      "  File \"<ipython-input-7-4336df07d4f2>\", line 106, in model_response\n",
      "    User_B = Sen_User_B[0]+\" \"+str(11-int(Sen_User_B[0])-int(Sen_User_B[3]))+\" \"+Sen_User_B[3]+\" \"+EMOTE_DELIMITER+User_B\n",
      "IndexError: string index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 -1\n",
      "(1, 30, 301)\n",
      "night night night ! ! ! go business business business business business business business business business business business business business business business business business business business business business business business\n"
     ]
    }
   ],
   "source": [
    "#KERAS_BACKEND=\"theano\"\n",
    "import numpy as np\n",
    "import word2vec_utils as w2v\n",
    "import data\n",
    "from data_utils import split_dataset \n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import model_from_json\n",
    "import subprocess\n",
    "import shlex\n",
    "import tkinter as tk\n",
    "from chat_constants import *\n",
    "try:\n",
    "    import ttk as ttk\n",
    "    import ScrolledText\n",
    "except ImportError:\n",
    "    import tkinter.ttk as ttk\n",
    "    import tkinter.scrolledtext as ScrolledText\n",
    "import time\n",
    "\n",
    "MODEL = 'AmergeB_len30_301dim_w2v_in_and_out.h5'\n",
    "REINFORCE = False\n",
    "\n",
    "class neural_chatbot():\n",
    "    \n",
    "    def __init__(self):\n",
    "        #self.initialize()\n",
    "        self.load_model()\n",
    "        self.w2v_model = w2v.initialize()\n",
    "        self.count=0\n",
    "        self.out='1 9 1 @Hi'\n",
    "        print( 'Loaded word_frequencies data from disk' )\n",
    "        self.word_freqs = np.load('words_in_order_of_freq.npy') \n",
    "        self.embed_dim = EMBED_DIM\n",
    "        self.data_dim = 1\n",
    "        self.timesteps = 26\n",
    "        self.vocab_size = 10000\n",
    "        self.emot_size = 4\n",
    "        self.max_sent_length = MAX_SENT_LENGTH\n",
    "        self.reinforce = 'neutral'\n",
    "    def save_model(self):\n",
    "        # serialize model to JSON\n",
    "        model_json = self.one_hot_chat_model.to_json()\n",
    "        with open(\"one_hot_chat_model.json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        self.one_hot_chat_model.save_weights(\"one_hot_chat_net.h5\")\n",
    "        print(\"Saved model to disk\")\n",
    "    \n",
    "    def load_model(self):\n",
    "        old_load = '''\n",
    "        # load json and create model\n",
    "        json_file = open('one_hot_chat_model.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        self.one_hot_chat_model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        self.one_hot_chat_model.load_weights(\"one_hot_chat_net.h5\")\n",
    "        '''\n",
    "        \n",
    "        self.model = keras.models.load_model(MODEL)\n",
    "        print(\"Loaded model from disk\")\n",
    "        \n",
    "    \n",
    "    def RateSentiment(self,sentiString):\n",
    "        #open a subprocess using shlex to get the command line string into the correct args list format\n",
    "        p = subprocess.Popen(shlex.split(\"/usr/bin/java -jar /home/paperspace/EmotionalChatBot/SentiStrength.jar stdin sentidata \\\n",
    "                                    /home/paperspace/EmotionalChatBot/SentStrength_Data_Sept2011/ \"),stdin=subprocess.PIPE,stdout=subprocess.PIPE,stderr=subprocess.PIPE,universal_newlines=True)\n",
    "        #communicate via stdin the string to be rated. Note that all spaces are replaced with +\n",
    "        stdout_text, stderr_text = p.communicate(sentiString.replace(\" \",\"+\"))\n",
    "        #remove the tab spacing between the positive and negative ratings. e.g. 1    -5 -> 1-5\n",
    "        stdout_text = stdout_text.rstrip().replace(\"\\t\",\"\")\n",
    "        return stdout_text   \n",
    "    \n",
    "            \n",
    "    def reinforcement_learn(self,user_emotion,sys_response):\n",
    "        total_emo = int(user_emotion[0]) - int(user_emotion[3])\n",
    "        sys_res = np.argmax(sys_response,axis=2)\n",
    "        adam = keras.optimizers.Adam(lr = 100)#default 0.001\n",
    "        self.one_hot_chat_model.compile( optimizer=adam,loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "        if total_emo > 0:\n",
    "            #sys_res = (10*sys_res)+10\n",
    "            sys_res_categorical=to_categorical(sys_res.astype(int),self.vocab_size+3).reshape((1,self.max_sent_length,self.vocab_size+3))\n",
    "            self.reinforce='positive'\n",
    "            self.one_hot_chat_model.fit(self.user_input,sys_res_categorical,epochs=3)\n",
    "        else:\n",
    "            sys_res_categorical=to_categorical(sys_res.astype(int),self.vocab_size+3).reshape((1,self.max_sent_length,self.vocab_size+3))*(-1)\n",
    "            self.reinforce='negative'\n",
    "            self.one_hot_chat_model.fit(self.user_input,sys_res_categorical,epochs=3)\n",
    "        self.save_model()\n",
    "        self.load_model()\n",
    "        \n",
    "    #def convert3d_to_4d(sys_response3d):\n",
    "    #    sys_res3d_standardized = (10*sys_res)+10\n",
    "    #    sys_response = to_categorical(sys_res3d_standardized.astype(int),20).reshape((1,300,-1,20))\n",
    "\n",
    "    def model_response(self,User_B):\n",
    "        #User_A1 = \"5 5 1 @I really love you. I think I want to marry you!\"\n",
    "        #User_B = \"1 5 5 @yeah well I hate you and never want to see you again! \"\n",
    "        #User_A1 = w2v.vectorize( w2v_model, User_A1 , pad_length = max_sent_length)\n",
    "        Sen_User_B = self.RateSentiment(User_B)\n",
    "        print(Sen_User_B)\n",
    "        self.count += 1\n",
    "        if REINFORCE and self.count>1:\n",
    "            self.reinforcement_learn(Sen_User_B,self.sys_prediction)\n",
    "        \n",
    "        User_B = Sen_User_B[0]+\" \"+str(11-int(Sen_User_B[0])-int(Sen_User_B[3]))+\" \"+Sen_User_B[3]+\" \"+EMOTE_DELIMITER+User_B\n",
    "        self.User_B_in  = w2v.vectorize( User_B, pad_length = MAX_SENT_LENGTH,model=self.w2v_model ) \n",
    "        User_A = w2v.vectorize( self.out, pad_length = MAX_SENT_LENGTH,model=self.w2v_model ) \n",
    "        self.user_input = [ np.array( [User_A]).reshape(1,MAX_SENT_LENGTH,EMBED_DIM), np.array([self.User_B_in]).reshape(1,MAX_SENT_LENGTH,EMBED_DIM) ]\n",
    "        #print(self.sys_prediction.shape)\n",
    "        self.sys_prediction = self.model.predict(self.user_input)\n",
    "        print(self.sys_prediction.shape)\n",
    "        sentence=np.argmax(self.sys_prediction,axis=2)\n",
    "        #w2v.one_hot_unvectorize(np.argmax(self.sys_prediction,axis=2))\n",
    "        pred_words=[]\n",
    "        for i in range(30):\n",
    "            pred_words.append(self.word_freqs[sentence[0,i]].decode('utf-8'))\n",
    "        self.out=\" \".join(pred_words)\n",
    "        print(self.out)    \n",
    "        return (self.out)\n",
    "        #sys_pred = np.argmax(prediction, axis=2)\n",
    "        #self.sys_prediction = (sys_pred-10)/10\n",
    "        #return self.most_likely_sent( self.sys_prediction[0], metadata['w2idx'].keys(),self.w2v_model)\n",
    "    \n",
    "class TkinterGUIExample(tk.Tk):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Create & set window variables.\n",
    "        \"\"\"\n",
    "        tk.Tk.__init__(self, *args, **kwargs)\n",
    "\n",
    "        self.title(\"Di-Feelbot\")\n",
    "        self.neuralbot = neural_chatbot()\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Set window layout.\n",
    "        \"\"\"\n",
    "        self.grid()\n",
    "\n",
    "        self.respond = ttk.Button(self, text='Get Response', command=self.get_response)\n",
    "        self.respond.grid(column=0, row=0, sticky='nesw', padx=3, pady=3)\n",
    "\n",
    "        self.usr_input = ttk.Entry(self, state='normal')\n",
    "        self.usr_input.grid(column=1, row=0, sticky='nesw', padx=3, pady=3)\n",
    "\n",
    "        self.conversation_lbl = ttk.Label(self, anchor=tk.E, text='Conversation:')\n",
    "        self.conversation_lbl.grid(column=0, row=5, sticky='nesw', padx=3, pady=3)\n",
    "\n",
    "        self.conversation = ScrolledText.ScrolledText(self, state='disabled')\n",
    "        self.conversation.grid(column=0, row=6, columnspan=2, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.emo_lbl = ttk.Label(self, text='Sys emotion')\n",
    "        self.emo_lbl.grid(column=0, row=1, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.emoPosvalue_lbl = ttk.Label(self, text='Pos emotion',foreground='blue')\n",
    "        self.emoPosvalue_lbl.grid(column=0, row=2, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.emoNegvalue_lbl = ttk.Label(self, text='Neg emotion',foreground='red')\n",
    "        self.emoNegvalue_lbl.grid(column=0, row=3, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.emoNeuvalue_lbl = ttk.Label(self, text='Neu emotion',foreground='black')\n",
    "        self.emoNeuvalue_lbl.grid(column=0, row=4, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.uemo_lbl = ttk.Label(self, text='User emotion')\n",
    "        self.uemo_lbl.grid(column=1, row=1, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.uemoPosvalue_lbl = ttk.Label(self, text='Pos emotion',foreground='blue')\n",
    "        self.uemoPosvalue_lbl.grid(column=1, row=2, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.uemoNegvalue_lbl = ttk.Label(self, text='Neg emotion',foreground='red')\n",
    "        self.uemoNegvalue_lbl.grid(column=1, row=3, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.uemoNeuvalue_lbl = ttk.Label(self, text='Neu emotion',foreground='black')\n",
    "        self.uemoNeuvalue_lbl.grid(column=1, row=4, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.reinforce_lbl = ttk.Label(self, text='Reinforcement',foreground='red')\n",
    "        self.reinforce_lbl.grid(column=2, row=1, sticky='nesw', padx=3, pady=3)\n",
    "    \n",
    "        \n",
    "    def get_response(self):\n",
    "        \"\"\"\n",
    "        Get a response from the chatbot and display it.\n",
    "        \"\"\"\n",
    "        user_input = self.usr_input.get()\n",
    "        self.usr_input.delete(0, tk.END)\n",
    "\n",
    "        response = self.neuralbot.model_response(user_input)\n",
    "        x=self.neuralbot.RateSentiment(user_input)\n",
    "        self.emoPosvalue_lbl['text'] = response[0]\n",
    "        self.emoNegvalue_lbl['text'] = response[4]\n",
    "        self.emoNeuvalue_lbl['text'] = response[2]\n",
    "        self.uemoPosvalue_lbl['text'] = x[0]\n",
    "        self.uemoNegvalue_lbl['text'] = x[3]\n",
    "        self.uemoNeuvalue_lbl['text'] = str(11-int(x[0])-int(x[3]))\n",
    "        self.reinforce_lbl['text'] = self.neuralbot.reinforce + ' Reinforcement'\n",
    "        self.conversation['state'] = 'normal'\n",
    "        self.conversation.insert(\n",
    "            tk.END, \"Human: \" + user_input + \"\\n\" + \"ChatBot: \" + str(response[7:]) + \"\\n\"\n",
    "        )\n",
    "        self.conversation['state'] = 'disabled'\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "w2v.unvectorize_initialize()\n",
    "gui_example = TkinterGUIExample()\n",
    "gui_example.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### BELOW IS SCRATCH #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 -4']\n",
      "1 -4\n"
     ]
    }
   ],
   "source": [
    "## Credit to http://sentistrength.wlv.ac.uk/documentation/Python.txt for the code\n",
    "from subprocess import *\n",
    "\n",
    "def jarWrapper(*args):\n",
    "    process = Popen(['java', '-jar']+list(args), stdout=PIPE, stderr=PIPE)\n",
    "    ret = []\n",
    "    while process.poll() is None:\n",
    "        line = process.stdout.readline()\n",
    "        if line != '' and line.endswith('\\n'):\n",
    "            ret.append(line[:-1])\n",
    "    stdout, stderr = process.communicate()\n",
    "    ret += stdout.split('\\n')\n",
    "    if stderr != '':\n",
    "        ret += stderr.split('\\n')\n",
    "    ret.remove('')\n",
    "    return ret\n",
    "\n",
    "args = ['/home/paperspace/EmotionalChatBot/SentiStrength.jar', 'text', 'hate','sentidata', '/home/paperspace/EmotionalChatBot/SentStrength_Data_Sept2011/'] # Any number of args to be passed to the jar file\n",
    "\n",
    "result = jarWrapper(*args)\n",
    "\n",
    "print(result)\n",
    "\n",
    "import shlex, subprocess\n",
    " \n",
    "def RateSentiment(sentiString):\n",
    "    #open a subprocess using shlex to get the command line string into the correct args list format\n",
    "    p = subprocess.Popen(shlex.split(\"/usr/bin/java -jar /home/paperspace/EmotionalChatBot/SentiStrength.jar stdin sentidata \\\n",
    "                                    /home/paperspace/EmotionalChatBot/SentStrength_Data_Sept2011/ \"),\n",
    "                         stdin=subprocess.PIPE,stdout=subprocess.PIPE,stderr=subprocess.PIPE,universal_newlines=True)\n",
    "    #communicate via stdin the string to be rated. Note that all spaces are replaced with +\n",
    "    stdout_text, stderr_text = p.communicate(sentiString.replace(\" \",\"+\"))\n",
    "    #remove the tab spacing between the positive and negative ratings. e.g. 1    -5 -> 1-5\n",
    "    stdout_text = stdout_text.rstrip().replace(\"\\t\",\"\")\n",
    "     \n",
    "\n",
    "    return stdout_text\n",
    "print(RateSentiment(\"I hate you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=RateSentiment('hate')\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to use global model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 301)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.vectorize('hello',pad_length=MAX_SENT_LENGTH).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anul\\Anaconda2\\envs\\python35\\lib\\site-packages\\ipykernel\\__main__.py:20: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(300, input_shape=(30, 300), dropout=0.2, return_sequences=True, recurrent_dropout=0.2)`\n",
      "C:\\Users\\anul\\Anaconda2\\envs\\python35\\lib\\site-packages\\ipykernel\\__main__.py:29: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(300, input_shape=(30, 300), dropout=0.2, return_sequences=True, recurrent_dropout=0.2)`\n",
      "C:\\Users\\anul\\Anaconda2\\envs\\python35\\lib\\site-packages\\ipykernel\\__main__.py:38: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\Users\\anul\\Anaconda2\\envs\\python35\\lib\\site-packages\\ipykernel\\__main__.py:39: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(300, dropout=0.2, return_sequences=True, recurrent_dropout=0.2)`\n",
      "C:\\Users\\anul\\Anaconda2\\envs\\python35\\lib\\site-packages\\ipykernel\\__main__.py:40: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(300, dropout=0.2, return_sequences=True, recurrent_dropout=0.2)`\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Embedding, TimeDistributed, Merge\n",
    "#from keras.utils.visualize_util import plot, to_graph\n",
    "#import theano.d3viz as d3v\n",
    "import word2vec_utils as w2v\n",
    "import data\n",
    "import numpy as np\n",
    "from data_utils import split_dataset \n",
    "\n",
    "embed_dim = 300\n",
    "data_dim = 1\n",
    "timesteps = 26\n",
    "vocab_size = 8100\n",
    "emot_size = 4\n",
    "max_sent_length = timesteps + emot_size\n",
    "\n",
    "model_A = Sequential()\n",
    "model_A.add(LSTM(embed_dim,input_shape=(max_sent_length,embed_dim),return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "\n",
    "model_A.compile(loss='cosine_proximity',\n",
    "      optimizer='rmsprop',\n",
    "      metrics=['accuracy']\n",
    "      )\n",
    "model_A.load_weights('model_A_weights.h5')\n",
    "\n",
    "model_B = Sequential()\n",
    "model_B.add(LSTM(embed_dim,input_shape=(max_sent_length,embed_dim),return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "\n",
    "model_B.compile(loss='cosine_proximity',\n",
    "      optimizer='rmsprop',\n",
    "      metrics=['accuracy']\n",
    "      )\n",
    "model_B.load_weights('model_B_weights.h5')\n",
    "\n",
    "model_ABA = Sequential()\n",
    "model_ABA.add(Merge([model_A, model_B], mode = 'concat'))\n",
    "model_ABA.add(LSTM(embed_dim,return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "model_ABA.add(LSTM(embed_dim,return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "#model_ABA.add(TimeDistributed(Dense(vocab_size,activation='softmax')))\n",
    "\n",
    "model_ABA.compile(loss='cosine_proximity',\n",
    "      optimizer='rmsprop',\n",
    "      metrics=['accuracy']\n",
    "      )\n",
    "model_ABA.load_weights('model_ABA_weights.h5')\n",
    "\n",
    "def cosign_similarity( a, b):\n",
    "    dot = np.dot(a,b)\n",
    "    norm = np.linalg.norm(a-b)\n",
    "    return( dot/norm )\n",
    "\n",
    "def most_likely_word( prediction, words, w2v_model ):\n",
    "    ret = \"\"\n",
    "    max_so_far = cosign_similarity( np.array([1]+[0]*299),prediction ) #must be better than blank\n",
    "    #Best word in dictionary\n",
    "    for word in words:\n",
    "        similarity = cosign_similarity( w2v.vectorize(w2v_model,word)[0], prediction )\n",
    "        if similarity > max_so_far:\n",
    "            max_so_far = similarity\n",
    "            ret = word    \n",
    "    return( ret )\n",
    "\n",
    "def most_likely_sent( prediction_vec, words, w2v_model ):\n",
    "    predicted_words = []\n",
    "    for prediction in prediction_vec:\n",
    "        predicted_words.append( most_likely_word(prediction,words,w2v_model))\n",
    "    ret = \" \".join(predicted_words)\n",
    "    return( ret )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = w2v.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.save_unknown_vectors({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.get_unknown_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.unvectorize_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 301)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected lstm_1_input to have 3 dimensions, but got array with shape (1, 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-039be23b4c68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUser_B\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0muser_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mUser_A1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUser_B\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_ABA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmost_likely_sent\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'w2idx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\anul\\Anaconda2\\envs\\python35\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\anul\\Anaconda2\\envs\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1560\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1561\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1562\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1563\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\anul\\Anaconda2\\envs\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    125\u001b[0m                                  \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                                  \u001b[1;34m' dimensions, but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected lstm_1_input to have 3 dimensions, but got array with shape (1, 30)"
     ]
    }
   ],
   "source": [
    "#unknown_vectors=[]\n",
    "User_A1 = \"5 5 1 @I really love you. I think I want to marry you!\"\n",
    "User_B = \"1 5 5 @yeah well I hate you and never want to see you again! \"\n",
    "User_A1 = w2v.vectorize( User_A1,model=w2v_model , pad_length = max_sent_length) \n",
    "User_B  = w2v.vectorize( User_B,model=w2v_model,  pad_length = max_sent_length)\n",
    "print(np.array([User_B[0]]).shape)\n",
    "user_input = [ np.array( [User_A1]), np.array([User_B]) ]\n",
    "prediction = model_ABA.predict(user_input)\n",
    "print(most_likely_sent( prediction[0], metadata['w2idx'].keys(),w2v_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "model_json = model_ABA.to_json()\n",
    "with open(\"model_ABA.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_ABA.save_weights(\"model_ABA.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\anul\\Anaconda2\\envs\\python2\\lib\\lib-tk\\Tkinter.py\", line 1542, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-2-de1a6c221b0b>\", line 94, in get_response\n",
      "    time.sleep(0.5)\n",
      "NameError: global name 'time' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\anul\\Anaconda2\\envs\\python2\\lib\\lib-tk\\Tkinter.py\", line 1542, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-2-de1a6c221b0b>\", line 94, in get_response\n",
      "    time.sleep(0.5)\n",
      "NameError: global name 'time' is not defined\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import shlex\n",
    "import Tkinter as tk\n",
    "try:\n",
    "    import ttk as ttk\n",
    "    import ScrolledText\n",
    "except ImportError:\n",
    "    import tkinter.ttk as ttk\n",
    "    import tkinter.scrolledtext as ScrolledText\n",
    "class TkinterGUIExample(tk.Tk):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Create & set window variables.\n",
    "        \"\"\"\n",
    "        tk.Tk.__init__(self, *args, **kwargs)\n",
    "\n",
    "        self.title(\"Di-Feelbot\")\n",
    "        #self.neuralbot = neural_chatbot()\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Set window layout.\n",
    "        \"\"\"\n",
    "        self.grid()\n",
    "\n",
    "        self.respond = ttk.Button(self, text='Get Response', command=self.get_response)\n",
    "        self.respond.grid(column=0, row=0, sticky='nesw', padx=3, pady=3)\n",
    "\n",
    "        self.usr_input = ttk.Entry(self, state='normal')\n",
    "        self.usr_input.grid(column=1, row=0, sticky='nesw', padx=3, pady=3)\n",
    "\n",
    "        self.conversation_lbl = ttk.Label(self, anchor=tk.E, text='Conversation:')\n",
    "        self.conversation_lbl.grid(column=0, row=5, sticky='nesw', padx=3, pady=3)\n",
    "\n",
    "        self.conversation = ScrolledText.ScrolledText(self, state='disabled')\n",
    "        self.conversation.grid(column=0, row=6, columnspan=2, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.emo_lbl = ttk.Label(self, text='Sys emotion')\n",
    "        self.emo_lbl.grid(column=0, row=1, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.emoPosvalue_lbl = ttk.Label(self, text='Pos emotion',foreground='blue')\n",
    "        self.emoPosvalue_lbl.grid(column=0, row=2, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.emoNegvalue_lbl = ttk.Label(self, text='Neg emotion',foreground='red')\n",
    "        self.emoNegvalue_lbl.grid(column=0, row=3, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.emoNeuvalue_lbl = ttk.Label(self, text='Neu emotion',foreground='black')\n",
    "        self.emoNeuvalue_lbl.grid(column=0, row=4, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.uemo_lbl = ttk.Label(self, text='User emotion')\n",
    "        self.uemo_lbl.grid(column=1, row=1, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.uemoPosvalue_lbl = ttk.Label(self, text='Pos emotion',foreground='blue')\n",
    "        self.uemoPosvalue_lbl.grid(column=1, row=2, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.uemoNegvalue_lbl = ttk.Label(self, text='Neg emotion',foreground='red')\n",
    "        self.uemoNegvalue_lbl.grid(column=1, row=3, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "        self.uemoNeuvalue_lbl = ttk.Label(self, text='Neu emotion',foreground='black')\n",
    "        self.uemoNeuvalue_lbl.grid(column=1, row=4, sticky='nesw', padx=3, pady=3)\n",
    "        \n",
    "    def RateSentiment(self,sentiString):\n",
    "        #open a subprocess using shlex to get the command line string into the correct args list format\n",
    "        p = subprocess.Popen(shlex.split(\"C:/ProgramData/Oracle/java/javapath/java -jar C:/Users/anul/Downloads/SentiStrength.jar stdin sentidata C:/Users/anul/Downloads/SentStrength_Data_Sept2011/\"),stdin=subprocess.PIPE,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "        #communicate via stdin the string to be rated. Note that all spaces are replaced with +\n",
    "        stdout_text, stderr_text = p.communicate(sentiString.replace(\" \",\"+\"))\n",
    "        #remove the tab spacing between the positive and negative ratings. e.g. 1    -5 -> 1-5\n",
    "        stdout_text = stdout_text.rstrip().replace(\"\\t\",\"\")\n",
    "        return stdout_text\n",
    "        \n",
    "    def get_response(self):\n",
    "        \"\"\"\n",
    "        Get a response from the chatbot and display it.\n",
    "        \"\"\"\n",
    "        user_input = self.usr_input.get()\n",
    "        self.usr_input.delete(0, tk.END)\n",
    "\n",
    "        response = '1 9 1 @Hi how are you'#self.neuralbot.model_response(user_input)\n",
    "        x=self.RateSentiment(user_input)\n",
    "        self.emoPosvalue_lbl['text'] = response[0]\n",
    "        self.emoNegvalue_lbl['text'] = response[4]\n",
    "        self.emoNeuvalue_lbl['text'] = response[2]\n",
    "        self.uemoPosvalue_lbl['text'] = x[0]\n",
    "        self.uemoNegvalue_lbl['text'] = x[3]\n",
    "        self.uemoNeuvalue_lbl['text'] = str(11-int(x[0])-int(x[3]))\n",
    "        self.conversation['state'] = 'normal'\n",
    "        self.conversation.insert(\n",
    "            tk.END, \"Human: \" + user_input + \"\\n\" + \"ChatBot: \" + str(response[7:]) + \"\\n\"\n",
    "        )\n",
    "        self.conversation['state'] = 'disabled'\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "\n",
    "gui_example = TkinterGUIExample()\n",
    "gui_example.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\anul\\Anaconda2\\envs\\python35\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 30, 101)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 30, 101)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)  (None, 30, 202)       164024      input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)  (None, 30, 202)       164024      input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "A1_layer2 (LSTM)                 (None, 30, 202)       327240      bidirectional_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "B_layer2 (LSTM)                  (None, 30, 202)       327240      bidirectional_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 30, 404)       0           A1_layer2[0][0]                  \n",
      "                                                                   B_layer2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "A2_layer1 (LSTM)                 (None, 30, 404)       1307344     concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistribu (None, 30, 10003)     4051215     A2_layer1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 6,341,087\n",
      "Trainable params: 6,341,087\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Embedding, TimeDistributed, concatenate, Input\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import word2vec_utils as w2v\n",
    "import data\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from data_utils import split_dataset \n",
    "from chat_constants import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "LSTM_DROPOUT = 0.15\n",
    "A1_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "A1_layer1 = Bidirectional( LSTM(EMBED_DIM,name = \"A1_layer1\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT) )\n",
    "A1_layer2 = LSTM(EMBED_DIM*2,name = \"A1_layer2\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A1_net = A1_layer2(A1_layer1(A1_input))\n",
    "\n",
    "B_input = Input(shape=(MAX_SENT_LENGTH,EMBED_DIM))\n",
    "\n",
    "B_layer1 = Bidirectional( LSTM(EMBED_DIM,name = \"B_layer1\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT) )\n",
    "B_layer2 = LSTM(EMBED_DIM*2,name = \"B_layer2\", return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "\n",
    "B_net = B_layer2(B_layer1(B_input))\n",
    "\n",
    "combined = concatenate([A1_net,B_net])\n",
    "A2_pred1 = LSTM(EMBED_DIM*4, name = \"A2_layer1\", return_sequences = True, dropout = LSTM_DROPOUT, recurrent_dropout=LSTM_DROPOUT)\n",
    "A2_pred2 = TimeDistributed(Dense(VOCAB_SIZE + 3, name = \"A2_layer2\", activation = 'softmax' ) )\n",
    "\n",
    "A2_net =A2_pred2(A2_pred1(combined))\n",
    "\n",
    "one_hot_chat_model = Model(inputs = [ A1_input,B_input], outputs = [A2_net])\n",
    "adam = keras.optimizers.Adam(lr = 0.01)#default 0.001\n",
    "one_hot_chat_model.compile( optimizer=adam,loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "one_hot_chat_model.summary()\n",
    "one_hot_chat_model.load_weights(\"one_hot_chat_net.h5\")\n",
    "print(\"Loaded model from disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = one_hot_chat_model.to_json()\n",
    "with open(\"one_hot_chat_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "one_hot_chat_model.save_weights(\"one_hot_chat_net.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b8146daa09b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mword_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'words_in_order_of_freq.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_freqs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "word_freqs = np.load('words_in_order_of_freq.npy') \n",
    "print(word_freqs.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
